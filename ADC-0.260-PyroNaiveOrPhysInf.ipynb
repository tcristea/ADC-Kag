{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":101849,"databundleVersionId":13093295,"sourceType":"competition"},{"sourceId":12303949,"sourceType":"datasetVersion","datasetId":7755350},{"sourceId":12309150,"sourceType":"datasetVersion","datasetId":7758622}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false},"papermill":{"default_parameters":{},"duration":46.011924,"end_time":"2025-06-28T07:57:11.831616","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2025-06-28T07:56:25.819692","version":"2.6.0"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"! uv pip install pyro-ppl[extras]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import time\nimport pickle\nimport numpy as np\nimport pandas as pd\nimport polars as pl\nimport functools\nimport os\nfrom tqdm import tqdm\nimport multiprocessing\n\n# Pyro and PyTorch imports\nimport torch\nimport pyro\nimport pyro.distributions as dist\nfrom pyro.nn import PyroModule, PyroSample\nfrom pyro.infer import SVI, Trace_ELBO, Predictive\nfrom pyro.infer.autoguide import AutoMultivariateNormal, AutoDiagonalNormal, AutoDelta, AutoNormalizingFlow\nfrom pyro.optim import Adam as PyroAdam\nimport torch.nn as nn\nfrom functools import partial\nfrom pyro.distributions.transforms import *\n\n# Traditional ML imports (fallback)\nimport scipy.stats\nimport xgboost as xgb\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.multioutput import MultiOutputRegressor\nimport pywt","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-06T00:53:47.601622Z","iopub.execute_input":"2025-08-06T00:53:47.602307Z","iopub.status.idle":"2025-08-06T00:53:47.614852Z","shell.execute_reply.started":"2025-08-06T00:53:47.602272Z","shell.execute_reply":"2025-08-06T00:53:47.613782Z"}},"outputs":[],"execution_count":85},{"cell_type":"code","source":"# ==============================================================================\n# PYRO MODELS\n# ==============================================================================\n\nclass SimplePyroModel(PyroModule):\n    \"\"\"Simple Bayesian neural network for comparison.\"\"\"\n    \n    def __init__(self, input_dim, output_dim=283):\n        super().__init__()\n        \n        self.network = PyroModule[nn.Sequential](\n            PyroModule[nn.Linear](input_dim, config.PYRO_HIDDEN_DIMS[0]),\n            PyroModule[nn.ReLU](),\n            PyroModule[nn.Dropout](0.1),\n            PyroModule[nn.Linear](config.PYRO_HIDDEN_DIMS[0], config.PYRO_HIDDEN_DIMS[1]),\n            PyroModule[nn.ReLU](),\n            PyroModule[nn.Dropout](0.1),\n            PyroModule[nn.Linear](config.PYRO_HIDDEN_DIMS[1], output_dim)\n        )\n        \n        # Set simple priors\n        for name, param in self.network.named_parameters():\n            if 'weight' in name:\n                setattr(self.network, name,\n                       PyroSample(dist.Normal(0., 0.5).expand(param.shape).to_event(param.dim())))\n            elif 'bias' in name:\n                setattr(self.network, name,\n                       PyroSample(dist.Normal(0., 0.1).expand(param.shape).to_event(param.dim())))\n\n    def forward(self, x, y=None):\n        mu = self.network(x)\n        \n        # Simple noise model\n        fgs_noise = pyro.sample(\"fgs_noise\", dist.LogNormal(-6., 0.3))\n        airs_noise = pyro.sample(\"airs_noise\", dist.LogNormal(-5., 0.3))\n        \n        noise_tensor = torch.zeros(x.shape[0], mu.shape[1], device=x.device)\n        noise_tensor[:, 0] = fgs_noise\n        noise_tensor[:, 1:] = airs_noise\n        \n        with pyro.plate(\"data\", x.shape[0]):\n            obs = pyro.sample(\"obs\", dist.Normal(mu, noise_tensor).to_event(1), obs=y)\n        \n        return mu","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-06T00:53:48.331646Z","iopub.execute_input":"2025-08-06T00:53:48.331954Z","iopub.status.idle":"2025-08-06T00:53:48.344266Z","shell.execute_reply.started":"2025-08-06T00:53:48.331930Z","shell.execute_reply":"2025-08-06T00:53:48.343165Z"}},"outputs":[],"execution_count":86},{"cell_type":"code","source":"class PhysicsInformedPyroModel(PyroModule):\n    \"\"\"Physics-informed model with sophisticated noise modeling.\"\"\"\n    \n    def __init__(self, input_dim, output_dim=283, feature_names=None, wavelengths=None):\n        super().__init__()\n        \n        self.feature_names = feature_names or []\n        self.wavelengths = wavelengths\n        self.output_dim = output_dim\n        \n        # Identify feature types\n        self.stellar_indices = self._find_feature_indices(['Rs', 'Ts', 'Ms', 'log_g'])\n        self.transit_indices = self._find_feature_indices(['fgs_slice', 'fgs_transit', 'fgs_snr'])\n        self.physics_indices = self._find_feature_indices(['stellar_density', 'equilibrium_temp'])\n        \n        # Build networks\n        self.stellar_net = self._build_network(len(self.stellar_indices), 32, 16) if self.stellar_indices else None\n        self.transit_net = self._build_network(len(self.transit_indices), 64, 32) if self.transit_indices else None\n        self.physics_net = self._build_network(len(self.physics_indices), 24, 12) if self.physics_indices else None\n        \n        # Remaining features\n        remaining_dim = input_dim - len(self.stellar_indices + self.transit_indices + self.physics_indices)\n        self.remaining_net = self._build_network(remaining_dim, 48, 24) if remaining_dim > 0 else None\n        \n        # Combiner\n        combiner_input = sum([net.hidden_dim for net in [self.stellar_net, self.transit_net, \n                             self.physics_net, self.remaining_net] if net is not None])\n        \n        self.combiner = PyroModule[nn.Sequential](\n            PyroModule[nn.Linear](combiner_input, 128),\n            PyroModule[nn.Tanh](),\n            PyroModule[nn.Dropout](0.15),\n            PyroModule[nn.Linear](128, 64),\n            PyroModule[nn.Tanh](),\n            PyroModule[nn.Linear](64, output_dim)\n        )\n        \n        self._set_physics_priors()\n    \n    def _find_feature_indices(self, keywords):\n        \"\"\"Find indices of features containing any of the keywords.\"\"\"\n        indices = []\n        for i, name in enumerate(self.feature_names):\n            if any(keyword.lower() in name.lower() for keyword in keywords):\n                indices.append(i)\n        return indices\n    \n    def _build_network(self, input_dim, hidden_dim, output_dim):\n        \"\"\"Build a simple network with stored hidden dimension.\"\"\"\n        if input_dim == 0:\n            return None\n        \n        net = PyroModule[nn.Sequential](\n            PyroModule[nn.Linear](input_dim, hidden_dim),\n            PyroModule[nn.Tanh](),\n            PyroModule[nn.Linear](hidden_dim, output_dim)\n        )\n        net.hidden_dim = output_dim  # Store for combiner calculation\n        return net\n    \n    def _set_physics_priors(self):\n        \"\"\"Set physics-informed priors.\"\"\"\n        # Stellar: tight priors (well-understood physics)\n        if self.stellar_net:\n            self._set_network_priors(self.stellar_net, weight_scale=0.3, bias_scale=0.05)\n        \n        # Transit: medium priors\n        if self.transit_net:\n            self._set_network_priors(self.transit_net, weight_scale=0.5, bias_scale=0.1)\n        \n        # Physics-derived: tight priors\n        if self.physics_net:\n            self._set_network_priors(self.physics_net, weight_scale=0.4, bias_scale=0.08)\n        \n        # Remaining: wide priors\n        if self.remaining_net:\n            self._set_network_priors(self.remaining_net, weight_scale=0.7, bias_scale=0.15)\n        \n        # Combiner: balanced priors\n        self._set_network_priors(self.combiner, weight_scale=0.5, bias_scale=0.1)\n    \n    def _set_network_priors(self, network, weight_scale, bias_scale):\n        \"\"\"Helper to set priors for a network.\"\"\"\n        for name, param in network.named_parameters():\n            if 'weight' in name:\n                setattr(network, name,\n                       PyroSample(dist.Normal(0.01, weight_scale).expand(param.shape).to_event(param.dim())))\n            elif 'bias' in name:\n                setattr(network, name,\n                       PyroSample(dist.Normal(0.01, bias_scale).expand(param.shape).to_event(param.dim())))\n\n    def forward(self, x, y=None):\n        batch_size = x.shape[0]\n        processed_features = []\n        \n        # Process different feature types\n        if self.stellar_net and self.stellar_indices:\n            stellar_processed = self.stellar_net(x[:, self.stellar_indices])\n            processed_features.append(stellar_processed)\n        \n        if self.transit_net and self.transit_indices:\n            transit_processed = self.transit_net(x[:, self.transit_indices])\n            processed_features.append(transit_processed)\n        \n        if self.physics_net and self.physics_indices:\n            physics_processed = self.physics_net(x[:, self.physics_indices])\n            processed_features.append(physics_processed)\n        \n        # Remaining features\n        all_processed = self.stellar_indices + self.transit_indices + self.physics_indices\n        remaining_indices = [i for i in range(x.shape[1]) if i not in all_processed]\n        \n        if self.remaining_net and remaining_indices:\n            remaining_processed = self.remaining_net(x[:, remaining_indices])\n            processed_features.append(remaining_processed)\n        \n        # Combine features\n        if processed_features:\n            combined = torch.cat(processed_features, dim=1)\n        else:\n            combined = x\n        \n        mu = self.combiner(combined)\n        \n        # Sample global noise parameters LOOK HERE\n        fgs_base_noise = pyro.sample(\"fgs_base_noise\", \n                                    dist.Normal(torch.tensor(0.015), torch.tensor(0.01)))\n        airs_base_noise = pyro.sample(\"airs_base_noise\", \n                                     dist.Normal(torch.tensor(0.0159), torch.tensor(0.012)))\n        \n        # Stellar temperature effects (if available)\n        if self.stellar_indices and len(self.stellar_indices) >= 2:\n            temp_effect = pyro.sample(\"temp_noise_effect\", \n                                     dist.Normal(torch.tensor(0.01), torch.tensor(0.01)))\n            stellar_temp = x[:, self.stellar_indices[1]]  # Assuming 2nd stellar feature is Ts\n            norm_temp = (stellar_temp - 5500) / 1000\n            temp_scaling = torch.abs(temp_effect * norm_temp)\n            \n            # Expand for batch\n            fgs_noise = fgs_base_noise * temp_scaling\n            airs_noise = airs_base_noise * temp_scaling\n        else:\n            # Expand scalars to match batch size\n            fgs_noise = fgs_base_noise.expand(batch_size)\n            airs_noise = airs_base_noise.expand(batch_size)\n        \n        # Wavelength-dependent scaling - make sure it's on correct device\n        with pyro.plate(\"output_wavelengths\", self.output_dim):\n            wavelength_scaling = pyro.sample(\"wavelength_scaling\",\n                                           dist.Normal(torch.zeros(self.output_dim, device=x.device) * 0.01, \n                                                        torch.ones(self.output_dim, device=x.device) * 0.01))\n        \n        # Construct noise tensor - ensure proper broadcasting\n        noise_tensor = torch.zeros(batch_size, self.output_dim, device=x.device)\n        \n        # FGS noise (first channel)\n        if isinstance(fgs_noise, torch.Tensor):\n            noise_tensor[:, 0] = fgs_noise * wavelength_scaling[0]\n        else:\n            noise_tensor[:, 0] = fgs_base_noise * wavelength_scaling[0]\n        \n        # AIRS noise (remaining channels)\n        for i in range(1, self.output_dim):\n            if isinstance(airs_noise, torch.Tensor):\n                noise_tensor[:, i] = airs_noise * wavelength_scaling[i]\n            else:\n                noise_tensor[:, i] = airs_base_noise * wavelength_scaling[i]\n        \n        # Ensure positive noise values\n        noise_tensor = torch.clamp(noise_tensor, min=1e-6)\n        \n        # Likelihood with proper plate\n        with pyro.plate(\"data\", batch_size):\n            obs = pyro.sample(\"obs\", \n                             dist.Normal(mu, noise_tensor).to_event(1), \n                             obs=y)\n        \n        return mu","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-06T01:46:43.839144Z","iopub.execute_input":"2025-08-06T01:46:43.839561Z","iopub.status.idle":"2025-08-06T01:46:43.905573Z","shell.execute_reply.started":"2025-08-06T01:46:43.839534Z","shell.execute_reply":"2025-08-06T01:46:43.904551Z"}},"outputs":[],"execution_count":97},{"cell_type":"code","source":"\ndef train_pyro_model_bak(X_train, y_train, X_val, y_val, feature_names=None, wavelengths=None,\n                         guide_type=\"auto\", flow_depth=2, flow_hidden_dims=None):\n    \"\"\"Train Pyro model with GPU support.\"\"\"\n    \n    print(f\"\\n--- Training {config.MODEL_TYPE.upper()} model ---\")\n    \n    # Convert to tensors and move to GPU\n    X_train_tensor = torch.FloatTensor(X_train.values if hasattr(X_train, 'values') else X_train).to(device)\n    y_train_tensor = torch.FloatTensor(y_train).to(device)\n    X_val_tensor = torch.FloatTensor(X_val.values if hasattr(X_val, 'values') else X_val).to(device)\n    y_val_tensor = torch.FloatTensor(y_val).to(device)\n    \n    # Clear parameter store\n    pyro.clear_param_store()\n    \n    # Initialize model\n    if config.MODEL_TYPE == 'physics_pyro':\n        model = PhysicsInformedPyroModel(\n            X_train_tensor.shape[1], \n            y_train_tensor.shape[1],\n            feature_names=feature_names,\n            wavelengths=wavelengths\n        ).to(device)\n    else:  # simple_pyro\n        model = SimplePyroModel(\n            X_train_tensor.shape[1],\n            y_train_tensor.shape[1]\n        ).to(device)\n    \n    print(\"Model created successfully\")\n    \n    # Prepare sample data for initialization\n    sample_x = X_train_tensor[:2].to(device)\n    sample_y = y_train_tensor[:2].to(device)\n    \n    # Try different guide approaches\n    guide = None\n    svi = None\n    setup_type = None\n    \n    print(\"=== Trying AutoMultivariateNormal ===\")\n    try:\n        guide = AutoNormalizingFlow(model, partial(iterated, 2, spline_autoregressive))\n        \n        # Initialize guide by running both model and guide\n        with torch.no_grad():\n            model(sample_x, sample_y)\n            guide(sample_x, sample_y)\n        \n        guide_params = list(guide.parameters())\n        print(f\"Guide parameters: {len(guide_params)}\")\n        \n        if len(guide_params) > 0:\n            optimizer = PyroAdam({\"lr\": config.PYRO_LR})\n            svi = SVI(model, guide, optimizer, loss=Trace_ELBO())\n            \n            # Test SVI step\n            test_loss = svi.step(sample_x, sample_y)\n            print(f\"✅ AutoMultivariateNormal SUCCESS! Test loss: {test_loss:.4f}\")\n            setup_type = \"AutoMultivariateNormal\"\n        else:\n            raise ValueError(\"No guide parameters created\")\n            \n    except Exception as e:\n        print(f\"❌ AutoMultivariateNormal failed: {e}\")\n        \n        print(\"=== Trying AutoDelta ===\")\n        try:\n            pyro.clear_param_store()\n            guide = AutoDelta(model)\n            \n            with torch.no_grad():\n                model(sample_x, sample_y)\n                guide(sample_x, sample_y)\n            \n            guide_params = list(guide.parameters())\n            print(f\"AutoDelta parameters: {len(guide_params)}\")\n            \n            if len(guide_params) > 0:\n                optimizer = PyroAdam({\"lr\": config.PYRO_LR})\n                svi = SVI(model, guide, optimizer, loss=Trace_ELBO())\n                \n                test_loss = svi.step(sample_x, sample_y)\n                print(f\"✅ AutoDelta SUCCESS! Test loss: {test_loss:.4f}\")\n                setup_type = \"AutoDelta\"\n            else:\n                raise ValueError(\"No AutoDelta parameters created\")\n                \n        except Exception as e2:\n            print(f\"❌ AutoDelta failed: {e2}\")\n            \n            print(\"=== Falling back to PyTorch training ===\")\n            # For PyTorch fallback, we need to modify the model's forward method\n            # to not use pyro.sample statements for regular training\n            print(\"❌ Pyro guides failed. You need to either:\")\n            print(\"1. Fix the pyro.sample statements in your model\")\n            print(\"2. Use a different training approach\")\n            print(\"3. Check that your model's forward method is compatible with Pyro\")\n            \n            return None, None, None\n    \n    if svi is None:\n        print(\"❌ Failed to create SVI - cannot proceed with training\")\n        return None, None, None\n    \n    print(f\"\\n🎉 Setup complete using: {setup_type}\")\n    \n    # Training loop with batching for GPU memory management\n    print(f\"Training for {config.PYRO_EPOCHS} epochs...\")\n    losses = []\n    \n    for epoch in range(config.PYRO_EPOCHS):\n        # Simple batch processing\n        if X_train_tensor.shape[0] > config.PYRO_BATCH_SIZE:\n            # Random batch for stochastic training\n            batch_idx = torch.randperm(X_train_tensor.shape[0])[:config.PYRO_BATCH_SIZE]\n            X_batch = X_train_tensor[batch_idx]\n            y_batch = y_train_tensor[batch_idx]\n        else:\n            X_batch = X_train_tensor\n            y_batch = y_train_tensor\n        \n        loss = svi.step(X_batch, y_batch)\n        losses.append(loss)\n        \n        if epoch % 100 == 0:\n            print(f\"  Epoch {epoch:4d}, Loss: {loss:8.2f}\")\n            if config.USE_GPU:\n                print(f\"  GPU Memory: {torch.cuda.memory_allocated(device) / 1e9:.1f} GB\")\n    \n    # Validation predictions\n    print(\"Generating validation predictions...\")\n    try:\n        predictive = Predictive(model, guide=guide, num_samples=config.PYRO_SAMPLES)\n        \n        with torch.no_grad():\n            val_predictions = predictive(X_val_tensor)\n            pred_samples = val_predictions['obs']\n            \n            # Move back to CPU for numpy operations\n            pred_samples_cpu = pred_samples.cpu()\n            \n            val_quantile_preds = {\n                0.05: torch.quantile(pred_samples_cpu, 0.05, dim=0).numpy(),\n                0.50: torch.quantile(pred_samples_cpu, 0.50, dim=0).numpy(),\n                0.95: torch.quantile(pred_samples_cpu, 0.95, dim=0).numpy()\n            }\n            \n    except Exception as e:\n        print(f\"⚠️ Prediction generation failed: {e}\")\n        print(\"Using model mean predictions instead...\")\n        \n        with torch.no_grad():\n            val_mean_pred = model(X_val_tensor).cpu().numpy()\n            val_quantile_preds = {\n                0.05: val_mean_pred * 0.95,  # Simple approximation\n                0.50: val_mean_pred,\n                0.95: val_mean_pred * 1.05\n            }\n    \n    print(f\"Training complete. Final loss: {losses[-1]:.2f}\")\n    return model.cpu(), guide, val_quantile_preds  # Move model back to CPU for saving\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-06T03:21:06.969389Z","iopub.execute_input":"2025-08-06T03:21:06.969807Z","iopub.status.idle":"2025-08-06T03:21:07.002772Z","shell.execute_reply.started":"2025-08-06T03:21:06.969779Z","shell.execute_reply":"2025-08-06T03:21:07.001757Z"}},"outputs":[],"execution_count":121},{"cell_type":"code","source":"import pyro.distributions.transforms as T\n\ndef train_pyro_model_WL(X_train, y_train, X_val, y_val, feature_names=None, wavelengths=None, \n                               guide_type=\"auto\", flow_depth=2, flow_hidden_dims=None):\n    \"\"\"\n    Train Pyro model with multiple guide options including normalizing flows.\n    \n    Args:\n        guide_type: \"auto\", \"mvn\", \"delta\", \"flow\"\n        flow_depth: Number of flow layers (for AutoNormalizingFlow)\n        flow_hidden_dims: Hidden dimensions for flow networks\n    \"\"\"\n    \n    print(f\"\\n--- Training {config.MODEL_TYPE.upper()} model with {guide_type.upper()} guide ---\")\n    \n    # Convert to tensors and move to GPU\n    X_train_tensor = torch.FloatTensor(X_train.values if hasattr(X_train, 'values') else X_train).to(device)\n    y_train_tensor = torch.FloatTensor(y_train).to(device)\n    X_val_tensor = torch.FloatTensor(X_val.values if hasattr(X_val, 'values') else X_val).to(device)\n    y_val_tensor = torch.FloatTensor(y_val).to(device)\n    \n    # Clear parameter store\n    pyro.clear_param_store()\n    \n    # Initialize model\n    if config.MODEL_TYPE == 'physics_pyro':\n        model = PhysicsInformedPyroModel(\n            X_train_tensor.shape[1], \n            y_train_tensor.shape[1],\n            feature_names=feature_names,\n            wavelengths=wavelengths\n        ).to(device)\n    else:  # simple_pyro\n        model = SimplePyroModel(\n            X_train_tensor.shape[1],\n            y_train_tensor.shape[1]\n        ).to(device)\n    \n    print(\"Model created successfully\")\n    \n    # Prepare sample data for initialization\n    sample_x = X_train_tensor[:2].to(device)\n    sample_y = y_train_tensor[:2].to(device)\n    \n    # Guide selection and setup\n    guide = None\n    svi = None\n    setup_type = None\n    \n    if guide_type == \"auto\":\n        # Try in order: AutoNormalizingFlow -> AutoMultivariateNormal -> AutoDelta\n        guide_attempts = [\"flow\", \"mvn\", \"delta\"]\n    else:\n        guide_attempts = [guide_type]\n    \n    for attempt in guide_attempts:\n        try:\n            print(f\"\\n=== Trying {attempt.upper()} ===\")\n            \n            if attempt == \"flow\":\n                # AutoNormalizingFlow setup\n                if flow_hidden_dims is None:\n                    flow_hidden_dims = [64, 64]  # Default architecture\n                print(f\"Flow config: depth={flow_depth}, hidden_dims={flow_hidden_dims}\")\n\n                flow_fn = partial(iterated, flow_depth, spline_autoregressive, hidden_dims=flow_hidden_dims)\n                                \n                guide = AutoNormalizingFlow(model, flow_fn)\n                \n                # Flows may need different learning rate\n                learning_rate = config.PYRO_LR * 0.5  # Often need slower LR for flows\n                \n            elif attempt == \"mvn\":\n                # AutoMultivariateNormal setup\n                guide = AutoMultivariateNormal(model)\n                learning_rate = config.PYRO_LR\n                \n            elif attempt == \"delta\":\n                # AutoDelta setup (point estimates)\n                guide = AutoDelta(model)\n                learning_rate = config.PYRO_LR\n                \n            # Initialize guide\n            pyro.clear_param_store()\n            \n            with torch.no_grad():\n                model(sample_x, sample_y)\n                guide(sample_x, sample_y)\n            \n            guide_params = list(guide.parameters())\n            print(f\"Guide parameters: {len(guide_params)}\")\n            \n            if len(guide_params) > 0:\n                # Create optimizer and SVI\n                optimizer = PyroAdam({\"lr\": learning_rate})\n                \n                # For flows, you might want to use different loss\n                if attempt == \"flow\":\n                    # Could use TraceMeanField_ELBO for better flow training\n                    loss_fn = Trace_ELBO()\n                else:\n                    loss_fn = Trace_ELBO()\n                \n                svi = SVI(model, guide, optimizer, loss=loss_fn)\n                \n                # Test SVI step\n                test_loss = svi.step(sample_x, sample_y)\n                print(f\"✅ {attempt.upper()} SUCCESS! Test loss: {test_loss:.4f}\")\n                setup_type = attempt.upper()\n                break\n            else:\n                raise ValueError(\"No guide parameters created\")\n                \n        except Exception as e:\n            print(f\"❌ {attempt.upper()} failed: {e}\")\n            if attempt == \"flow\":\n                print(\"   Flow failure often due to:\")\n                print(\"   - Complex model (try simpler flow_depth=1)\")\n                print(\"   - Memory constraints (reduce hidden_dims)\")\n                print(\"   - Numerical instability (try smaller LR)\")\n            continue\n    \n    if svi is None:\n        print(\"❌ All guide attempts failed - cannot proceed with training\")\n        return None, None, None\n    \n    print(f\"\\n🎉 Setup complete using: {setup_type}\")\n    \n    # Adjusted training parameters based on guide type\n    if setup_type == \"FLOW\":\n        # Flows often need more epochs and different scheduling\n        epochs = int(config.PYRO_EPOCHS * 1.5)  # 50% more epochs\n        print_interval = 50  # Print more frequently\n        print(\"🔥 Using Normalizing Flow - expect slower but more expressive training\")\n    else:\n        epochs = config.PYRO_EPOCHS\n        print_interval = 100\n    \n    # Training loop with batching for GPU memory management\n    print(f\"Training for {epochs} epochs...\")\n    losses = []\n    \n    for epoch in range(epochs):\n        # Simple batch processing\n        if X_train_tensor.shape[0] > config.PYRO_BATCH_SIZE:\n            # For flows, you might want smaller batches due to memory\n            batch_size = config.PYRO_BATCH_SIZE if setup_type != \"FLOW\" else config.PYRO_BATCH_SIZE // 2\n            batch_idx = torch.randperm(X_train_tensor.shape[0])[:batch_size]\n            X_batch = X_train_tensor[batch_idx]\n            y_batch = y_train_tensor[batch_idx]\n        else:\n            X_batch = X_train_tensor\n            y_batch = y_train_tensor\n        \n        loss = svi.step(X_batch, y_batch)\n        losses.append(loss)\n        \n        if epoch % print_interval == 0:\n            print(f\"  Epoch {epoch:4d}, Loss: {loss:8.2f}\")\n            if config.USE_GPU:\n                print(f\"  GPU Memory: {torch.cuda.memory_allocated(device) / 1e9:.1f} GB\")\n    \n    # Validation predictions\n    print(\"Generating validation predictions...\")\n    try:\n        # For flows, you might want more samples for better uncertainty estimates\n        num_samples = config.PYRO_SAMPLES if setup_type != \"FLOW\" else min(config.PYRO_SAMPLES * 2, 1000)\n        \n        predictive = Predictive(model, guide=guide, num_samples=num_samples)\n        \n        print(f\"Using {num_samples} samples for predictions...\")\n        \n        with torch.no_grad():\n            # For flows, process in smaller chunks to avoid memory issues\n            if setup_type == \"FLOW\" and X_val_tensor.shape[0] > 100:\n                print(\"Processing validation in chunks for memory efficiency...\")\n                chunk_size = 50\n                all_predictions = []\n                \n                for i in range(0, X_val_tensor.shape[0], chunk_size):\n                    chunk = X_val_tensor[i:i+chunk_size]\n                    chunk_pred = predictive(chunk)['obs']\n                    all_predictions.append(chunk_pred)\n                \n                pred_samples = torch.cat(all_predictions, dim=1)  # Concat along sample dimension\n            else:\n                val_predictions = predictive(X_val_tensor)\n                pred_samples = val_predictions['obs']\n            \n            # Move back to CPU for numpy operations\n            pred_samples_cpu = pred_samples.cpu()\n            \n            val_quantile_preds = {\n                0.05: torch.quantile(pred_samples_cpu, 0.05, dim=0).numpy(),\n                0.50: torch.quantile(pred_samples_cpu, 0.50, dim=0).numpy(),\n                0.95: torch.quantile(pred_samples_cpu, 0.95, dim=0).numpy()\n            }\n            \n            # For flows, also compute additional uncertainty metrics\n            if setup_type == \"FLOW\":\n                print(\"Computing flow-specific uncertainty metrics...\")\n                pred_mean = torch.mean(pred_samples_cpu, dim=0).numpy()\n                pred_std = torch.std(pred_samples_cpu, dim=0).numpy()\n                \n                # Add these to results\n                val_quantile_preds.update({\n                    'mean': pred_mean,\n                    'std': pred_std,\n                    'samples_shape': pred_samples_cpu.shape\n                })\n            \n    except Exception as e:\n        print(f\"⚠️ Prediction generation failed: {e}\")\n        print(\"Using model mean predictions instead...\")\n        \n        with torch.no_grad():\n            val_mean_pred = model(X_val_tensor).cpu().numpy()\n            val_quantile_preds = {\n                0.05: val_mean_pred * 0.95,  # Simple approximation\n                0.50: val_mean_pred,\n                0.95: val_mean_pred * 1.05\n            }\n    \n    print(f\"Training complete. Final loss: {losses[-1]:.2f}\")\n    print(f\"Guide type used: {setup_type}\")\n    \n    return model.cpu(), guide, val_quantile_preds  # Move model back to CPU for saving\n\n\n# Helper function to compare different guides\ndef compare_guides(X_train, y_train, X_val, y_val, feature_names=None, wavelengths=None):\n    \"\"\"Compare different guide types on the same data.\"\"\"\n    \n    results = {}\n    guide_types = [\"mvn\", \"flow\", \"delta\"]\n    \n    for guide_type in guide_types:\n        print(f\"\\n{'='*50}\")\n        print(f\"TESTING {guide_type.upper()}\")\n        print(f\"{'='*50}\")\n        \n        try:\n            model, guide, predictions = train_pyro_model(\n                X_train, y_train, X_val, y_val,\n                feature_names=feature_names,\n                wavelengths=wavelengths,\n                guide_type=guide_type,\n                flow_depth=1,  # Simpler flow for comparison\n                flow_hidden_dims=[32, 32]\n            )\n            \n            if predictions is not None:\n                results[guide_type] = {\n                    'model': model,\n                    'guide': guide, \n                    'predictions': predictions,\n                    'success': True\n                }\n            else:\n                results[guide_type] = {'success': False}\n                \n        except Exception as e:\n            print(f\"❌ {guide_type} completely failed: {e}\")\n            results[guide_type] = {'success': False, 'error': str(e)}\n    \n    # Print summary\n    print(f\"\\n{'='*50}\")\n    print(\"COMPARISON SUMMARY\")\n    print(f\"{'='*50}\")\n    \n    for guide_type, result in results.items():\n        if result['success']:\n            print(f\"✅ {guide_type.upper()}: SUCCESS\")\n        else:\n            print(f\"❌ {guide_type.upper()}: FAILED\")\n    \n    return results","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-06T03:21:15.819246Z","iopub.execute_input":"2025-08-06T03:21:15.819625Z","iopub.status.idle":"2025-08-06T03:21:15.850464Z","shell.execute_reply.started":"2025-08-06T03:21:15.819573Z","shell.execute_reply":"2025-08-06T03:21:15.849651Z"}},"outputs":[],"execution_count":122},{"cell_type":"code","source":"import pyro\nimport torch\nfrom pyro.infer.autoguide import AutoMultivariateNormal, AutoDelta, AutoLowRankMultivariateNormal\nfrom pyro.infer import SVI, Trace_ELBO, Predictive\nfrom pyro.optim import Adam as PyroAdam\n\ndef train_pyro_model(X_train, y_train, X_val, y_val, feature_names=None, wavelengths=None,\n                         guide_type=\"auto\", flow_depth=2, flow_hidden_dims=None):\n    \"\"\"\n    Improved training with better guide choices for physics models.\n    \"\"\"\n    \n    print(f\"\\n--- Improved Training for {config.MODEL_TYPE.upper()} model ---\")\n    \n    # Convert to tensors and move to GPU\n    X_train_tensor = torch.FloatTensor(X_train.values if hasattr(X_train, 'values') else X_train).to(device)\n    y_train_tensor = torch.FloatTensor(y_train).to(device)\n    X_val_tensor = torch.FloatTensor(X_val.values if hasattr(X_val, 'values') else X_val).to(device)\n    y_val_tensor = torch.FloatTensor(y_val).to(device)\n    \n    # Clear parameter store\n    pyro.clear_param_store()\n    \n    # Initialize model\n    if config.MODEL_TYPE == 'physics_pyro':\n        model = PhysicsInformedPyroModel(\n            X_train_tensor.shape[1], \n            y_train_tensor.shape[1],\n            feature_names=feature_names,\n            wavelengths=wavelengths\n        ).to(device)\n    else:\n        model = SimplePyroModel(\n            X_train_tensor.shape[1],\n            y_train_tensor.shape[1]\n        ).to(device)\n    \n    print(\"Model created successfully\")\n    \n    # Prepare sample data\n    sample_x = X_train_tensor[:4].to(device)  # Use more samples for initialization\n    sample_y = y_train_tensor[:4].to(device)\n    \n    print(\"\\n=== Strategy 1: AutoLowRankMultivariateNormal ===\")\n    print(\"(Better than full MVN for high-dimensional problems)\")\n    \n    try:\n        # Low-rank approximation - good for high-dimensional posteriors\n        rank = min(50, X_train_tensor.shape[1])  # Adaptive rank\n        guide = AutoLowRankMultivariateNormal(model, rank=rank)\n        \n        with torch.no_grad():\n            model(sample_x, sample_y)\n            guide(sample_x, sample_y)\n        \n        guide_params = list(guide.parameters())\n        print(f\"Low-rank guide parameters: {len(guide_params)}\")\n        \n        if len(guide_params) > 0:\n            optimizer = PyroAdam({\"lr\": config.PYRO_LR})\n            svi = SVI(model, guide, optimizer, loss=Trace_ELBO())\n            \n            test_loss = svi.step(sample_x, sample_y)\n            print(f\"✅ Low-rank MVN SUCCESS! Test loss: {test_loss:.4f}\")\n            \n            # Train with low-rank guide\n            model_lr, predictions_lr = train_with_guide(model, guide, svi, X_train_tensor, y_train_tensor, X_val_tensor)\n            return model_lr, guide, predictions_lr\n            \n    except Exception as e:\n        print(f\"❌ Low-rank MVN failed: {e}\")\n    \n    print(\"\\n=== Strategy 2: AutoDelta (Point Estimates) ===\")\n    print(\"(Often most reliable for complex physics models)\")\n    \n    try:\n        pyro.clear_param_store()\n        guide = AutoDelta(model)\n        \n        with torch.no_grad():\n            model(sample_x, sample_y)\n            guide(sample_x, sample_y)\n        \n        guide_params = list(guide.parameters())\n        print(f\"Delta guide parameters: {len(guide_params)}\")\n        \n        if len(guide_params) > 0:\n            # Use higher learning rate for point estimates\n            optimizer = PyroAdam({\"lr\": config.PYRO_LR * 2})\n            svi = SVI(model, guide, optimizer, loss=Trace_ELBO())\n            \n            test_loss = svi.step(sample_x, sample_y)\n            print(f\"✅ AutoDelta SUCCESS! Test loss: {test_loss:.4f}\")\n            \n            # Train with delta guide\n            model_delta, predictions_delta = train_with_guide(model, guide, svi, X_train_tensor, y_train_tensor, X_val_tensor)\n            return model_delta, guide, predictions_delta\n            \n    except Exception as e:\n        print(f\"❌ AutoDelta failed: {e}\")\n    \n    print(\"\\n=== Strategy 3: Simplified Model ===\")\n    print(\"(Reduce complexity by focusing on key physics parameters)\")\n    \n    # Create a simpler version focusing only on the key Pyro sample sites\n    try:\n        # This would require modifying your model to have fewer pyro.sample statements\n        # Focus only on the most important physics parameters\n        print(\"Consider simplifying your model by:\")\n        print(\"1. Using fewer pyro.sample statements\")\n        print(\"2. Fixing some parameters instead of sampling them\")\n        print(\"3. Using stronger priors to regularize\")\n        \n    except Exception as e:\n        print(f\"❌ Model simplification guidance: {e}\")\n    \n    print(\"❌ All approaches failed - model may be too complex for current setup\")\n    return None, None, None\n\n\ndef train_with_guide(model, guide, svi, X_train_tensor, y_train_tensor, X_val_tensor):\n    \"\"\"Helper function to train with a given guide and return predictions.\"\"\"\n    \n    print(f\"Training for {config.PYRO_EPOCHS} epochs...\")\n    losses = []\n    \n    for epoch in range(config.PYRO_EPOCHS):\n        # Batch processing\n        if X_train_tensor.shape[0] > config.PYRO_BATCH_SIZE:\n            batch_idx = torch.randperm(X_train_tensor.shape[0])[:config.PYRO_BATCH_SIZE]\n            X_batch = X_train_tensor[batch_idx]\n            y_batch = y_train_tensor[batch_idx]\n        else:\n            X_batch = X_train_tensor\n            y_batch = y_train_tensor\n        \n        loss = svi.step(X_batch, y_batch)\n        losses.append(loss)\n        \n        if epoch % 200 == 0:\n            print(f\"  Epoch {epoch:4d}, Loss: {loss:8.2f}\")\n    \n    # Generate predictions\n    print(\"Generating predictions...\")\n    try:\n        # Use fewer samples for faster prediction\n        predictive = Predictive(model, guide=guide, num_samples=min(100, config.PYRO_SAMPLES))\n        \n        with torch.no_grad():\n            val_predictions = predictive(X_val_tensor)\n            pred_samples = val_predictions['obs'].cpu()\n            \n            val_quantile_preds = {\n                0.05: torch.quantile(pred_samples, 0.05, dim=0).numpy(),\n                0.50: torch.quantile(pred_samples, 0.50, dim=0).numpy(),\n                0.95: torch.quantile(pred_samples, 0.95, dim=0).numpy()\n            }\n            \n    except Exception as e:\n        print(f\"Prediction failed, using model mean: {e}\")\n        with torch.no_grad():\n            val_mean_pred = model(X_val_tensor).cpu().numpy()\n            val_quantile_preds = {\n                0.05: val_mean_pred * 0.95,\n                0.50: val_mean_pred,\n                0.95: val_mean_pred * 1.05\n            }\n    \n    print(f\"Training complete. Final loss: {losses[-1]:.2f}\")\n    return model.cpu(), val_quantile_preds\n\n\ndef diagnose_model_complexity(model, X_sample, y_sample):\n    \"\"\"Diagnose why the model might be having issues.\"\"\"\n    \n    print(\"\\n=== Model Complexity Diagnosis ===\")\n    \n    # Count model parameters\n    model_params = list(model.parameters())\n    total_params = sum(p.numel() for p in model_params)\n    print(f\"Neural network parameters: {total_params:,}\")\n    \n    # Count Pyro sample sites\n    from pyro.poutine import trace\n    with torch.no_grad():\n        tr = trace(model).get_trace(X_sample, y_sample)\n        sample_sites = [name for name, site in tr.nodes.items() if site[\"type\"] == \"sample\"]\n        pyro_params = sum(site[\"value\"].numel() for name, site in tr.nodes.items() \n                         if site[\"type\"] == \"sample\" and hasattr(site[\"value\"], \"numel\"))\n    \n    print(f\"Pyro sample sites: {len(sample_sites)}\")\n    print(f\"Pyro parameters: {pyro_params}\")\n    print(f\"Sample site names: {sample_sites}\")\n    print(f\"Total latent dimension: ~{total_params + pyro_params:,}\")\n    \n    # Data-to-parameter ratio\n    data_points = X_sample.shape[0] * X_sample.shape[1]  # Approximate\n    ratio = data_points / (total_params + pyro_params)\n    print(f\"Data-to-parameter ratio: {ratio:.2f}\")\n    \n    if ratio < 1:\n        print(\"⚠️  WARNING: Very few data points per parameter - model likely overparameterized\")\n    elif ratio < 5:\n        print(\"⚠️  WARNING: Low data-to-parameter ratio - consider regularization\")\n    else:\n        print(\"✅ Reasonable data-to-parameter ratio\")\n    \n    return {\n        'nn_params': total_params,\n        'pyro_params': pyro_params,\n        'sample_sites': sample_sites,\n        'data_ratio': ratio\n    }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-06T03:48:45.098823Z","iopub.execute_input":"2025-08-06T03:48:45.099141Z","iopub.status.idle":"2025-08-06T03:48:45.123275Z","shell.execute_reply.started":"2025-08-06T03:48:45.099117Z","shell.execute_reply":"2025-08-06T03:48:45.122352Z"}},"outputs":[],"execution_count":127},{"cell_type":"code","source":"import pyro\nimport torch\nimport numpy as np\nfrom pyro.infer.autoguide import AutoMultivariateNormal, AutoDelta\nfrom pyro.infer import SVI, Trace_ELBO, Predictive\nfrom pyro.optim import Adam as PyroAdam\n\ndef debug_pyro_model(model, X_train_tensor, y_train_tensor, X_val_tensor, y_val_tensor):\n    \"\"\"Debug why the Pyro model isn't learning correctly.\"\"\"\n    \n    print(\"=== DEBUGGING PYRO MODEL ===\")\n    \n    # 1. Check data preprocessing\n    print(f\"X_train range: [{X_train_tensor.min():.4f}, {X_train_tensor.max():.4f}]\")\n    print(f\"y_train range: [{y_train_tensor.min():.4f}, {y_train_tensor.max():.4f}]\")\n    print(f\"X_val range: [{X_val_tensor.min():.4f}, {X_val_tensor.max():.4f}]\")\n    print(f\"y_val range: [{y_val_tensor.min():.4f}, {y_val_tensor.max():.4f}]\")\n    \n    # 2. Test model without Pyro (deterministic forward pass)\n    print(\"\\n=== Testing Deterministic Model ===\")\n    with torch.no_grad():\n        # Get the neural network output (mu) without pyro.sample\n        sample_x = X_val_tensor[:10]\n        sample_y = y_val_tensor[:10]\n        \n        # This will include pyro.sample, but we can extract mu\n        try:\n            model_output = model(sample_x, sample_y)  # This returns mu\n            print(f\"Model mu range: [{model_output.min():.6f}, {model_output.max():.6f}]\")\n            print(f\"Model mu mean/std: {model_output.mean():.6f} / {model_output.std():.6f}\")\n            print(f\"Target mean/std: {sample_y.mean():.6f} / {sample_y.std():.6f}\")\n            \n            # Check if the neural network part is reasonable\n            if abs(model_output.mean().item() - sample_y.mean().item()) > 0.01:\n                print(\"⚠️  WARNING: Model mean output is very different from target!\")\n                print(\"   This suggests the neural network isn't learning properly\")\n        except Exception as e:\n            print(f\"Model forward pass failed: {e}\")\n    \n    # 3. Check noise parameters\n    print(\"\\n=== Checking Noise Parameters ===\")\n    from pyro.poutine import trace\n    \n    with torch.no_grad():\n        tr = trace(model).get_trace(sample_x, sample_y)\n        \n        for name, site in tr.nodes.items():\n            if site[\"type\"] == \"sample\" and \"noise\" in name:\n                value = site[\"value\"]\n                print(f\"{name}: {value.mean():.6f} ± {value.std():.6f}\")\n                \n                # Check if noise is reasonable\n                if \"base_noise\" in name and value.mean() > 0.1:\n                    print(f\"⚠️  WARNING: {name} seems too large!\")\n                elif \"base_noise\" in name and value.mean() < 1e-8:\n                    print(f\"⚠️  WARNING: {name} seems too small!\")\n    \n    # 4. Check for gradient flow\n    print(\"\\n=== Checking Gradient Flow ===\")\n    return True\n\ndef create_fixed_pyro_model(X_train_tensor, y_train_tensor, feature_names=None, wavelengths=None):\n    \"\"\"Create a corrected version of the physics model.\"\"\"\n    \n    # Let's create a simpler, more reliable version\n    class FixedPhysicsInformedPyroModel(pyro.nn.PyroModule):\n        def __init__(self, input_dim, output_dim, feature_names=None, wavelengths=None):\n            super().__init__()\n            \n            self.feature_names = feature_names or []\n            self.wavelengths = wavelengths\n            self.output_dim = output_dim\n            \n            # Simplified architecture - single network\n            self.network = pyro.nn.PyroModule[torch.nn.Sequential](\n                pyro.nn.PyroModule[torch.nn.Linear](input_dim, 128),\n                pyro.nn.PyroModule[torch.nn.ReLU](),\n                pyro.nn.PyroModule[torch.nn.Dropout](0.1),\n                pyro.nn.PyroModule[torch.nn.Linear](128, 64),\n                pyro.nn.PyroModule[torch.nn.ReLU](),\n                pyro.nn.PyroModule[torch.nn.Linear](64, output_dim)\n            )\n        \n        def forward(self, x, y=None):\n            # Neural network prediction\n            mu = self.network(x)\n            \n            # Simplified noise model - single global noise parameter\n            # Use more conservative priors\n            noise_scale = pyro.sample(\"global_noise\", \n                                    pyro.distributions.LogNormal(\n                                        torch.tensor(-4.0, device=x.device),  # exp(-4) ≈ 0.018\n                                        torch.tensor(0.5, device=x.device)    # More concentrated\n                                    ))\n            \n            # Expand noise to match batch and output dimensions\n            noise_tensor = noise_scale.expand(x.shape[0], self.output_dim)\n            \n            # Likelihood\n            with pyro.plate(\"data\", x.shape[0]):\n                obs = pyro.sample(\"obs\", \n                                pyro.distributions.Normal(mu, noise_tensor).to_event(1), \n                                obs=y)\n            \n            return mu\n    \n    return FixedPhysicsInformedPyroModel(\n        X_train_tensor.shape[1], \n        y_train_tensor.shape[1], \n        feature_names=feature_names, \n        wavelengths=wavelengths\n    ).to(X_train_tensor.device)\n\ndef train_pyro_model(X_train, y_train, X_val, y_val, feature_names=None, wavelengths=None,\n                         guide_type=\"auto\", flow_depth=2, flow_hidden_dims=None):\n    \"\"\"Train with a simplified, more reliable model.\"\"\"\n    \n    print(\"=== TRAINING FIXED PYRO MODEL ===\")\n    \n    # Convert to tensors\n    X_train_tensor = torch.FloatTensor(X_train.values if hasattr(X_train, 'values') else X_train).to(device)\n    y_train_tensor = torch.FloatTensor(y_train).to(device)\n    X_val_tensor = torch.FloatTensor(X_val.values if hasattr(X_val, 'values') else X_val).to(device)\n    y_val_tensor = torch.FloatTensor(y_val).to(device)\n    \n    # Debug original model first\n    print(\"First, let's debug your original model...\")\n    original_model = PhysicsInformedPyroModel(\n        X_train_tensor.shape[1], \n        y_train_tensor.shape[1],\n        feature_names=feature_names,\n        wavelengths=wavelengths\n    ).to(device)\n    \n    debug_pyro_model(original_model, X_train_tensor, y_train_tensor, X_val_tensor, y_val_tensor)\n    \n    # Create fixed model\n    print(\"\\n=== Creating Fixed Model ===\")\n    pyro.clear_param_store()\n    \n    fixed_model = create_fixed_pyro_model(X_train_tensor, y_train_tensor, feature_names, wavelengths)\n    \n    # Use AutoDelta for reliability\n    guide = AutoDelta(fixed_model)\n    \n    # Initialize\n    sample_x = X_train_tensor[:4]\n    sample_y = y_train_tensor[:4]\n    \n    with torch.no_grad():\n        fixed_model(sample_x, sample_y)\n        guide(sample_x, sample_y)\n    \n    # Training setup\n    optimizer = PyroAdam({\"lr\": config.PYRO_LR})\n    svi = SVI(fixed_model, guide, optimizer, loss=Trace_ELBO())\n    \n    print(f\"Training fixed model for {config.PYRO_EPOCHS} epochs...\")\n    losses = []\n    \n    # Track predictions during training\n    pred_means = []\n    \n    for epoch in range(config.PYRO_EPOCHS):\n        # Batch processing\n        if X_train_tensor.shape[0] > config.PYRO_BATCH_SIZE:\n            batch_idx = torch.randperm(X_train_tensor.shape[0])[:config.PYRO_BATCH_SIZE]\n            X_batch = X_train_tensor[batch_idx]\n            y_batch = y_train_tensor[batch_idx]\n        else:\n            X_batch = X_train_tensor\n            y_batch = y_train_tensor\n        \n        loss = svi.step(X_batch, y_batch)\n        losses.append(loss)\n        \n        # Track progress\n        if epoch % 100 == 0:\n            with torch.no_grad():\n                pred_sample = fixed_model(X_val_tensor[:10])\n                pred_mean = pred_sample.mean().item()\n                pred_means.append(pred_mean)\n                \n                print(f\"  Epoch {epoch:4d}, Loss: {loss:8.2f}, Pred Mean: {pred_mean:.6f}\")\n    \n    # Final predictions\n    print(\"Generating final predictions...\")\n    with torch.no_grad():\n        pred_mean = fixed_model(X_val_tensor)\n        \n        # For AutoDelta, we don't have uncertainty, so create approximate bounds\n        noise_param = pyro.param(\"AutoDelta.global_noise\").exp()\n        noise_std = noise_param.mean().item()\n        \n        pred_mean_np = pred_mean.cpu().numpy()\n        \n        val_quantile_preds = {\n            0.05: pred_mean_np - 1.645 * noise_std,\n            0.50: pred_mean_np, \n            0.95: pred_mean_np + 1.645 * noise_std\n        }\n    \n    # Evaluation\n    pred_mean_final = pred_mean_np.mean()\n    pred_std_final = pred_mean_np.std()\n    \n    print(f\"\\n=== FIXED MODEL RESULTS ===\")\n    print(f\"y_val mean/std: {y_val_tensor.mean():.6f} {y_val_tensor.std():.6f}\")\n    print(f\"Pred mean/std: {pred_mean_final:.6f} {pred_std_final:.6f}\")\n    print(f\"Final loss: {losses[-1]:.2f}\")\n    print(f\"Noise parameter: {noise_std:.6f}\")\n    \n    return fixed_model.cpu(), guide, val_quantile_preds\n\n\n# Quick fix for your existing model - adjust the priors\ndef suggest_prior_fixes():\n    \"\"\"Suggest better priors for your existing model.\"\"\"\n    \n    print(\"=== SUGGESTED FIXES FOR YOUR EXISTING MODEL ===\")\n    print()\n    print(\"In your PhysicsInformedPyroModel.forward(), try these changes:\")\n    print()\n    print(\"1. ADJUST NOISE PRIORS (current priors might be too broad):\")\n    print(\"   OLD: pyro.sample('fgs_base_noise', dist.LogNormal(-6.0, 0.2))\")\n    print(\"   NEW: pyro.sample('fgs_base_noise', dist.LogNormal(-4.0, 0.3))\")\n    print()\n    print(\"   OLD: pyro.sample('airs_base_noise', dist.LogNormal(-5.0, 0.2))\")  \n    print(\"   NEW: pyro.sample('airs_base_noise', dist.LogNormal(-4.0, 0.3))\")\n    print()\n    print(\"2. SIMPLIFY WAVELENGTH SCALING:\")\n    print(\"   OLD: dist.LogNormal(0., 0.1).expand((self.output_dim,))\")\n    print(\"   NEW: dist.LogNormal(0., 0.05).expand((self.output_dim,))  # Less variation\")\n    print()\n    print(\"3. CONSTRAIN TEMPERATURE EFFECTS:\")\n    print(\"   OLD: pyro.sample('temp_noise_effect', dist.Normal(0., 0.1))\")\n    print(\"   NEW: pyro.sample('temp_noise_effect', dist.Normal(0., 0.05))  # Smaller effect\")\n    print()\n    print(\"4. ADD OUTPUT SCALING:\")\n    print(\"   After mu = self.combiner(combined), add:\")\n    print(\"   mu = torch.sigmoid(mu) * y_scale  # where y_scale is max of your targets\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-06T03:57:02.700572Z","iopub.execute_input":"2025-08-06T03:57:02.700960Z","iopub.status.idle":"2025-08-06T03:57:02.728646Z","shell.execute_reply.started":"2025-08-06T03:57:02.700933Z","shell.execute_reply":"2025-08-06T03:57:02.727758Z"}},"outputs":[],"execution_count":134},{"cell_type":"code","source":"# ==============================================================================\n# COMPLETE PYRO PIPELINE: Ariel Data Challenge 2025 \n# Features: Simple/Physics-Informed Pyro models, GPU support, submission handling\n# ==============================================================================\nclass Config:\n    \"\"\"Enhanced configuration with Pyro and GPU support.\"\"\"\n    \n    # Paths\n    DATA_PATH = '/kaggle/input/ariel-data-challenge-2025/'\n    PREPROCESSED_PATH = '/kaggle/input/ariel-data-challenge-2025-af-npy/'\n    OUTPUT_PATH = '/kaggle/working/ariel-data-2025-27'\n    \n    TRAIN_LABELS_PATH = os.path.join(DATA_PATH, 'train.csv')\n    TRAIN_STAR_INFO_PATH = os.path.join(DATA_PATH, 'train_star_info.csv')\n    TEST_STAR_INFO_PATH = os.path.join(DATA_PATH, 'test_star_info.csv')\n    SAMPLE_SUBMISSION_PATH = os.path.join(DATA_PATH, 'sample_submission.csv')\n    WAVELENGTHS_PATH = os.path.join(DATA_PATH, 'wavelengths.csv')\n    A_RAW_PATH = os.path.join(PREPROCESSED_PATH, \"a_raw_train.npy\")\n    F_RAW_PATH = os.path.join(PREPROCESSED_PATH, \"f_raw_train.npy\")\n    \n    # Model selection\n    MODEL_TYPE = 'physics_pyro'  # Options: 'xgboost', 'simple_pyro', 'physics_pyro'\n    \n    # GPU Configuration\n    USE_GPU = False\n    GPU_DEVICE = 'cuda:0'  # Change to 'cuda:1' for second GPU if needed\n    \n    # Pyro hyperparameters\n    PYRO_EPOCHS = 1000\n    PYRO_LR = 0.000005\n    PYRO_BATCH_SIZE = 32  # For GPU memory management\n    PYRO_SAMPLES = 200\n    PYRO_HIDDEN_DIMS = [128, 64, 32]\n    \n    # Physics model options\n    USE_WAVELENGTH_PHYSICS = True\n    ADD_DERIVED_PHYSICS_FEATURES = True\n    SUN_TEMP = 5500 # Sun (5778 K)\n    TEMP_SCALING_FACTOR = 1000 # this is a scaling factor t\n    # o convert temperature differences to a reasonable numerical range (typically -2 to +2) for neural networks\n    SIGMA_SCALLING = 3.29 # 90% Use 2.58 for 99% confidence intervals (instead of 90%)\n    \n    # Traditional parameters (fallback)\n    VALIDATION_SPLIT = 0.1\n    RANDOM_STATE = 42\n    QUANTILES = [0.05, 0.50, 0.95]\n    XGB_PARAMS = {\n        'n_estimators': 400,\n        'learning_rate': 0.04,\n        'max_depth': 6,\n        'subsample': 0.8,\n        'colsample_bytree': 0.7,\n        'random_state': 42,\n        'tree_method': 'hist',\n    }\n\nconfig = Config()\n\n# GPU Setup\ndef setup_gpu():\n    \"\"\"Setup GPU configuration for PyTorch and Pyro.\"\"\"\n    if config.USE_GPU and torch.cuda.is_available():\n        device = torch.device(config.GPU_DEVICE)\n        print(f\"Using GPU: {torch.cuda.get_device_name(device)}\")\n        print(f\"GPU Memory: {torch.cuda.get_device_properties(device).total_memory / 1e9:.1f} GB\")\n        \n        # Optimize for GPU\n        torch.backends.cudnn.benchmark = True\n        torch.cuda.empty_cache()\n        \n        return device\n    else:\n        print(\"Using CPU\")\n        return torch.device('cpu')\n\ndevice = setup_gpu()\n\n# ==============================================================================\n# DATA PREPROCESSING (Your existing functions)\n# ==============================================================================\n\ndef f_read_and_preprocess(dataset, planet_ids):\n    \"\"\"Read the FGS1 files for all planet_ids and extract the time series.\"\"\"\n    print(f\"Preprocessing FGS1 data for {dataset} set...\")\n    f_raw_data = np.full((len(planet_ids), 67500), np.nan, dtype=np.float32)\n    for i, planet_id in tqdm(list(enumerate(planet_ids)), desc=\"FGS1\"):\n        path = f'/kaggle/input/ariel-data-challenge-2025/{dataset}/{int(planet_id)}/FGS1_signal_0.parquet'\n        f_signal = pl.read_parquet(path)\n        mean_signal = f_signal.cast(pl.Int32).sum_horizontal().cast(pl.Float32).to_numpy() / 1024\n        net_signal = mean_signal[1::2] - mean_signal[0::2]\n        f_raw_data[i] = net_signal\n    return f_raw_data\n\ndef a_read_and_preprocess(dataset, planet_ids):\n    \"\"\"Read the AIRS-CH0 files for all planet_ids and extract the time series.\"\"\"\n    print(f\"Preprocessing AIRS-CH0 data for {dataset} set...\")\n    a_raw_data = np.full((len(planet_ids), 5625), np.nan, dtype=np.float32)\n    for i, planet_id in tqdm(list(enumerate(planet_ids)), desc=\"AIRS-CH0\"):\n        path = f'/kaggle/input/ariel-data-challenge-2025/{dataset}/{int(planet_id)}/AIRS-CH0_signal_0.parquet'\n        signal = pl.read_parquet(path)\n        mean_signal = signal.cast(pl.Int32).sum_horizontal().cast(pl.Float32).to_numpy() / (32*356)\n        net_signal = mean_signal[1::2] - mean_signal[0::2]\n        a_raw_data[i] = net_signal\n    return a_raw_data\n\ndef official_competition_score(y_true, y_pred, sigma_pred, naive_mean, naive_sigma,\n                               fsg_sigma_true=1e-6, airs_sigma_true=1e-5, fgs_weight=2.0):\n    \"\"\"Official weighted Gaussian Log-Likelihood metric.\"\"\"\n    y_true, y_pred, sigma_pred = np.array(y_true), np.array(y_pred), np.array(sigma_pred)\n    sigma_pred = np.clip(sigma_pred, 1e-15, None)\n\n    sigma_true_per_channel = np.append(np.array([fsg_sigma_true]), np.ones(y_true.shape[1] - 1) * airs_sigma_true)\n    sigma_true = np.tile(sigma_true_per_channel, (y_true.shape[0], 1))\n\n    GLL_pred = scipy.stats.norm.logpdf(y_true, loc=y_pred, scale=sigma_pred)\n    GLL_true = scipy.stats.norm.logpdf(y_true, loc=y_true, scale=sigma_true)\n    GLL_mean = scipy.stats.norm.logpdf(y_true, loc=naive_mean, scale=naive_sigma)\n    \n    denominator = GLL_true - GLL_mean\n    ind_scores = (GLL_pred - GLL_mean) / (denominator + 1e-9)\n\n    weights_per_channel = np.append(np.array([fgs_weight]), np.ones(y_true.shape[1] - 1))\n    weights = np.tile(weights_per_channel, (y_true.shape[0], 1))\n\n    final_score = np.average(ind_scores, weights=weights)\n    return float(np.clip(final_score, 0.0, 1.0))\n\ndef maximal_feature_engineering(f_raw, a_raw, star_info_df):\n    \"\"\"Your existing feature engineering function.\"\"\"\n    print(\"Engineering features...\")\n    \n    fgs_pre = f_raw[:, :20500]; fgs_post = f_raw[:, 47000:]\n    fgs_unobscured_mean = (fgs_pre.mean(axis=1) + fgs_post.mean(axis=1)) / 2\n    fgs_unobscured_std = (fgs_pre.std(axis=1) + fgs_post.std(axis=1)) / 2\n    fgs_transit = f_raw[:, 23500:44000]\n    \n    features = {}\n    for i in range(5):\n        f_slice_mean = fgs_transit[:, i*4100:(i+1)*4100].mean(axis=1)\n        features[f'fgs_slice_{i+1}'] = (fgs_unobscured_mean - f_slice_mean) / fgs_unobscured_mean\n    \n    features['fgs_transit_std'] = fgs_transit.std(axis=1)\n    features['fgs_transit_skew'] = scipy.stats.skew(fgs_transit, axis=1)\n    features['fgs_transit_kurtosis'] = scipy.stats.kurtosis(fgs_transit, axis=1)\n    features['fgs_snr'] = (fgs_unobscured_mean - fgs_transit.mean(axis=1)) / fgs_unobscured_std\n    features_df = pd.DataFrame(features, index=star_info_df.index)\n\n    fft_coeffs = np.fft.fft(fgs_transit, axis=1)\n    for i in range(1, 6):\n        features_df[f'fgs_fft_mag_{i}'] = np.abs(fft_coeffs[:, i])\n    for level in range(1, 4):\n        coeffs = pywt.wavedec(fgs_transit, 'db4', level=level, axis=1)\n        features_df[f'fgs_wavelet_std_level{level}'] = np.std(coeffs[0], axis=1)\n        features_df[f'fgs_wavelet_mean_level{level}'] = np.mean(coeffs[0], axis=1)\n\n    meta_df = star_info_df.copy().fillna(star_info_df.median())\n    meta_df['log_g_proxy'] = np.log1p(meta_df['Ms']) - 2 * np.log1p(meta_df['Rs'])\n    meta_df['rho_star_proxy'] = meta_df['Ms'] / (meta_df['Rs']**3)\n    \n    poly = PolynomialFeatures(degree=2, include_bias=False, interaction_only=True)\n    poly_cols = ['Rs', 'Ts', 'Mp', 'P']\n    poly_features = poly.fit_transform(meta_df[poly_cols])\n    poly_df = pd.DataFrame(poly_features, columns=poly.get_feature_names_out(poly_cols), index=meta_df.index)\n    \n    final_features_df = pd.concat([features_df, meta_df, poly_df], axis=1)\n    final_features_df = final_features_df.loc[:, ~final_features_df.columns.duplicated()]\n\n    if config.ADD_DERIVED_PHYSICS_FEATURES:\n        final_features_df = add_derived_physics_features(final_features_df, meta_df)\n\n    print(f\"Created {final_features_df.shape[1]} features in total.\")\n    return final_features_df.fillna(0)\n\ndef add_derived_physics_features(features_df, star_info_df):\n    \"\"\"Add physics-derived features.\"\"\"\n    enhanced_df = features_df.copy()\n    \n    if 'Rs' in star_info_df.columns and 'Ms' in star_info_df.columns:\n        enhanced_df['stellar_density'] = star_info_df['Ms'] / (star_info_df['Rs'] ** 3)\n        enhanced_df['log_g_calculated'] = np.log10(star_info_df['Ms'] / (star_info_df['Rs'] ** 2))\n    \n    if 'Mp' in star_info_df.columns and 'P' in star_info_df.columns:\n        enhanced_df['semi_major_axis'] = ((star_info_df['P'] / 365.25) ** (2/3) * \n                                        star_info_df['Ms'] ** (1/3))\n        \n        if 'Ts' in star_info_df.columns and 'Rs' in star_info_df.columns:\n            enhanced_df['equilibrium_temp'] = (star_info_df['Ts'] * \n                                             np.sqrt(star_info_df['Rs'] / \n                                                   (2 * enhanced_df['semi_major_axis'])))\n    \n    return enhanced_df\n\ndef train_xgboost_quantiles(X_train, y_train, X_val, y_val):\n    \"\"\"Fallback XGBoost training.\"\"\"\n    print(\"\\\\n--- Training XGBoost Quantile Models ---\")\n    \n    val_quantile_preds = {}\n    for q in config.QUANTILES:\n        print(f\"Training quantile: {q}\")\n        model = xgb.XGBRegressor(**config.XGB_PARAMS, objective='reg:quantileerror', quantile_alpha=q)\n        wrapper = MultiOutputRegressor(model, n_jobs=-1)\n        wrapper.fit(X_train, y_train)\n        val_quantile_preds[q] = wrapper.predict(X_val)\n    \n    return val_quantile_preds\n\n# ==============================================================================\n# SUBMISSION FUNCTIONS\n# ==============================================================================\n\ndef make_pyro_predictions(model, guide, X_test, feature_names=None, wavelengths=None):\n    \"\"\"Make predictions with trained Pyro model.\"\"\"\n    \n    print(\"Making Pyro predictions...\")\n    \n    # Recreate model architecture for loading\n    if config.MODEL_TYPE == 'physics_pyro':\n        model_for_prediction = PhysicsInformedPyroModel(\n            X_test.shape[1], 283,\n            feature_names=feature_names,\n            wavelengths=wavelengths\n        ).to(device)\n    else:\n        model_for_prediction = SimplePyroModel(X_test.shape[1], 283).to(device)\n    \n    # Load state if model is provided as path\n    if isinstance(model, str):\n        model_for_prediction.load_state_dict(torch.load(model, map_location=device))\n        guide.load_state_dict(torch.load(model.replace('model', 'guide'), map_location=device))\n        model = model_for_prediction\n    else:\n        model = model.to(device)\n    \n    X_test_tensor = torch.FloatTensor(X_test.values if hasattr(X_test, 'values') else X_test).to(device)\n    \n    predictive = Predictive(model, guide=guide, num_samples=config.PYRO_SAMPLES)\n    \n    with torch.no_grad():\n        # Process in batches to manage GPU memory\n        all_predictions = []\n        batch_size = min(config.PYRO_BATCH_SIZE, X_test_tensor.shape[0])\n        \n        for i in range(0, X_test_tensor.shape[0], batch_size):\n            X_batch = X_test_tensor[i:i+batch_size]\n            batch_predictions = predictive(X_batch)\n            all_predictions.append(batch_predictions['obs'].cpu())\n        \n        # Combine all predictions\n        pred_samples = torch.cat(all_predictions, dim=1)\n        \n        test_quantile_preds = {\n            0.05: torch.quantile(pred_samples, 0.05, dim=0).numpy(),\n            0.50: torch.quantile(pred_samples, 0.50, dim=0).numpy(),\n            0.95: torch.quantile(pred_samples, 0.95, dim=0).numpy()\n        }\n    \n    return test_quantile_preds\n\ndef save_models(model, guide, feature_names, output_path):\n    \"\"\"Save models and metadata.\"\"\"\n    os.makedirs(output_path, exist_ok=True)\n    \n    if config.MODEL_TYPE in ['simple_pyro', 'physics_pyro']:\n        torch.save(model.state_dict(), os.path.join(output_path, 'pyro_model.pth'))\n        torch.save(guide.state_dict(), os.path.join(output_path, 'pyro_guide.pth'))\n        \n        # Save model metadata\n        metadata = {\n            'model_type': config.MODEL_TYPE,\n            'feature_names': feature_names,\n            'input_dim': len(feature_names),\n            'output_dim': 283\n        }\n        \n        with open(os.path.join(output_path, 'model_metadata.pkl'), 'wb') as f:\n            pickle.dump(metadata, f)\n        \n        print(f\"Pyro models saved to: {output_path}\")\n    \n    # Always save feature columns for compatibility\n    with open(os.path.join(output_path, 'feature_columns.pkl'), 'wb') as f:\n        pickle.dump(feature_names, f)\n\ndef load_models(output_path):\n    \"\"\"Load saved models and metadata.\"\"\"\n    \n    # Load metadata\n    with open(os.path.join(output_path, 'model_metadata.pkl'), 'rb') as f:\n        metadata = pickle.load(f)\n    \n    with open(os.path.join(output_path, 'feature_columns.pkl'), 'rb') as f:\n        feature_names = pickle.load(f)\n    \n    # Load appropriate model\n    if metadata['model_type'] == 'physics_pyro':\n        model = PhysicsInformedPyroModel(\n            metadata['input_dim'], \n            metadata['output_dim'],\n            feature_names=metadata['feature_names']\n        )\n    elif metadata['model_type'] == 'simple_pyro':\n        model = SimplePyroModel(\n            metadata['input_dim'],\n            metadata['output_dim']\n        )\n    else:\n        raise ValueError(f\"Unknown model type: {metadata['model_type']}\")\n    \n    # Load model states\n    model.load_state_dict(torch.load(os.path.join(output_path, 'pyro_model.pth'), map_location='cpu'))\n    \n    guide = AutoMultivariateNormal(model)\n    guide.load_state_dict(torch.load(os.path.join(output_path, 'pyro_guide.pth'), map_location='cpu'))\n    \n    return model, guide, feature_names, metadata\n\n# ==============================================================================\n# MAIN EXECUTION PIPELINE\n# ==============================================================================\n\ndef main():\n    \"\"\"Main execution pipeline with model switching.\"\"\"\n    \n    print(f\"\\\\nUsing model: {config.MODEL_TYPE}\")\n    print(f\"Device: {device}\")\n    if config.USE_GPU:\n        print(f\"GPU: {torch.cuda.get_device_name(device)}\")\n    \n    is_submission_run = False # os.path.exists(config.TEST_STAR_INFO_PATH)\n\n    if is_submission_run:\n        # --- SUBMISSION MODE ---\n        print(\"\\\\n\" + \"=\"*60)\n        print(\"======         SUBMISSION MODE          ======\")\n        print(\"=\"*60 + \"\\\\n\")\n\n        # Load test data\n        sample_submission = pd.read_csv(config.SAMPLE_SUBMISSION_PATH, index_col='planet_id')\n        test_star_info_df = pd.read_csv(config.TEST_STAR_INFO_PATH, index_col='planet_id')\n        wavelengths_df = pd.read_csv(config.WAVELENGTHS_PATH)\n        target_column_names = wavelengths_df.columns.tolist()\n\n        # Process test data\n        f_raw_test = f_read_and_preprocess('test', test_star_info_df.index)\n        a_raw_test = a_read_and_preprocess('test', test_star_info_df.index)\n        test_features_df = maximal_feature_engineering(f_raw_test, a_raw_test, test_star_info_df)\n        \n        # Load models and make predictions\n        if config.MODEL_TYPE in ['simple_pyro', 'physics_pyro']:\n            try:\n                model, guide, feature_names, metadata = load_models(config.OUTPUT_PATH)\n                test_features_df = test_features_df[feature_names]\n                \n                # Get wavelengths for physics model\n                wavelengths = None\n                if config.MODEL_TYPE == 'physics_pyro' and config.USE_WAVELENGTH_PHYSICS:\n                    try:\n                        # Extract wavelengths from column names\n                        wavelengths = []\n                        for col in target_column_names:\n                            if col.startswith('wl_'):\n                                try:\n                                    wl_val = float(col.replace('wl_', ''))\n                                    wavelengths.append(wl_val)\n                                except:\n                                    wavelengths.append(len(wavelengths) + 1)\n                    except:\n                        wavelengths = None\n                \n                test_quantile_preds = make_pyro_predictions(\n                    model, guide, test_features_df, feature_names, wavelengths\n                )\n                \n            except Exception as e:\n                print(f\"Error loading Pyro model: {e}\")\n                print(\"Falling back to XGBoost...\")\n                config.MODEL_TYPE = 'xgboost'\n        \n        if config.MODEL_TYPE == 'xgboost':\n            # Load XGBoost models (your existing code)\n            with open(os.path.join(config.OUTPUT_PATH, 'feature_columns.pkl'), 'rb') as f:\n                train_cols = pickle.load(f)\n            \n            test_features_df = test_features_df[train_cols]\n            \n            trained_models = {}\n            for q in config.QUANTILES:\n                model_path = os.path.join(config.OUTPUT_PATH, f'model_quantile_{q}.pkl')\n                with open(model_path, 'rb') as f:\n                    trained_models[q] = pickle.load(f)\n            \n            test_quantile_preds = {}\n            for q in config.QUANTILES:\n                test_quantile_preds[q] = trained_models[q].predict(test_features_df)\n\n        # Create submission\n        y_pred_test = test_quantile_preds[0.50].clip(0, None)\n        lower_test, upper_test = test_quantile_preds[0.05], test_quantile_preds[0.95]\n        \n        sigma_raw_test = (upper_test - lower_test) / 3.29\n        sigma_raw_test[sigma_raw_test < 0] = 1e-10\n        \n        # For Pyro models, uncertainties are better calibrated, but we can still apply minimal scaling\n        if config.MODEL_TYPE in ['simple_pyro', 'physics_pyro']:\n            sigma_pred_test = sigma_raw_test * 1.1  # Minimal adjustment for Pyro\n        else:\n            # Load calibration for XGBoost\n            try:\n                with open(os.path.join(config.OUTPUT_PATH, 'calibration_params.pkl'), 'rb') as f:\n                    calibration_params = pickle.load(f)\n                sigma_pred_test = (sigma_raw_test * calibration_params['scaling']) + calibration_params['additive']\n            except:\n                sigma_pred_test = sigma_raw_test * 1.2  # Default scaling\n        \n        # Format submission\n        pred_df = pd.DataFrame(y_pred_test, index=sample_submission.index, columns=target_column_names)\n        sigma_df = pd.DataFrame(sigma_pred_test, index=sample_submission.index, \n                               columns=[f\"sigma_{i+1}\" for i in range(len(target_column_names))])\n        submission_df = pd.concat([pred_df, sigma_df], axis=1)\n        \n        submission_df.to_csv('submission.csv')\n        print(\"\\\\n'submission.csv' created successfully!\")\n        print(f\"\\\\nSubmission preview ({config.MODEL_TYPE}):\")\n        print(submission_df.head())\n\n    else:\n        # --- TRAINING MODE ---\n        print(\"\\\\n\" + \"=\"*60)\n        print(\"======          TRAINING MODE           ======\")\n        print(\"=\"*60 + \"\\\\n\")\n        \n        # Load training data\n        train_labels_df = pd.read_csv(config.TRAIN_LABELS_PATH, index_col='planet_id')\n        train_star_info_df = pd.read_csv(config.TRAIN_STAR_INFO_PATH, index_col='planet_id').loc[train_labels_df.index]\n        \n        print(\"Loading pre-processed training data...\")\n        f_raw_train, a_raw_train = np.load(config.F_RAW_PATH), np.load(config.A_RAW_PATH)\n        \n        train_features_df = maximal_feature_engineering(f_raw_train, a_raw_train, train_star_info_df)\n        train_labels = train_labels_df.values\n        naive_mu_train, naive_sigma_train = np.mean(train_labels), np.std(train_labels)\n\n        # Train-validation split\n        X_train, X_val, y_train, y_val = train_test_split(\n            train_features_df, train_labels, \n            test_size=config.VALIDATION_SPLIT, \n            random_state=config.RANDOM_STATE\n        )\n        \n        feature_names = train_features_df.columns.tolist()\n        \n        # Get wavelengths for physics model\n        wavelengths = None\n        if config.MODEL_TYPE == 'physics_pyro' and config.USE_WAVELENGTH_PHYSICS:\n            try:\n                wavelengths_df = pd.read_csv(config.WAVELENGTHS_PATH)\n                wavelengths = []\n                for col in wavelengths_df.columns:\n                    if col.startswith('wl_'):\n                        try:\n                            wl_val = float(col.replace('wl_', ''))\n                            wavelengths.append(wl_val)\n                        except:\n                            wavelengths.append(len(wavelengths) + 1)\n            except:\n                print(\"Could not load wavelengths, using default indexing\")\n                wavelengths = None\n\n        # Train model based on selection\n        if config.MODEL_TYPE in ['simple_pyro', 'physics_pyro']:\n            # Train Pyro model\n            model, guide, val_quantile_preds = train_pyro_model(\n                X_train, y_train, X_val, y_val, feature_names, wavelengths, guide_type=\"flow\", flow_depth=1,  # Start with depth=1 for stability\n                flow_hidden_dims=[1024, 1024]  # Much larger hidden dims\n            )\n            \n            # Evaluate\n            y_pred_val = val_quantile_preds[0.50]\n            lower_val, upper_val = val_quantile_preds[0.05], val_quantile_preds[0.95]\n            sigma_raw_val = (upper_val - lower_val) / 3.29\n            sigma_raw_val[sigma_raw_val < 0] = 1e-10\n            \n            # Minimal calibration for Pyro (they're usually well-calibrated)\n            sigma_val = sigma_raw_val * 1.1\n            \n            pyro_score = official_competition_score(\n                y_val, y_pred_val, sigma_val, naive_mu_train, naive_sigma_train\n            )\n            \n            print(f\"\\\\n{config.MODEL_TYPE.upper()} Validation Score: {pyro_score:.4f}\")\n            \n            # Save models\n            save_models(model, guide, feature_names, config.OUTPUT_PATH)\n            # First model's prediction and evaluation\n            y_pred_val = val_quantile_preds[0.50]\n            lower_val, upper_val = val_quantile_preds[0.05], val_quantile_preds[0.95]\n            sigma_raw_val = (upper_val - lower_val) / 3.29\n            sigma_raw_val[sigma_raw_val < 0] = 1e-10\n            sigma_val = sigma_raw_val * 1.1\n            \n            print(\"DIAGNOSTICS AS PER CHAT 1:\")\n            abs_err = np.abs(y_val - y_pred_val)\n            normed_err = abs_err / sigma_val\n            print(\"Mean absolute error:\", abs_err.mean())\n            print(\"Mean normalized error:\", normed_err.mean())\n            print(\"Max normalized error:\", normed_err.max())\n            print(\"Min normalized error:\", normed_err.min())\n            print(\"END DIAGNOSTICS AS PER CHAT 1\")\n\n            import matplotlib.pyplot as plt\n\n            plt.scatter(y_pred_val, sigma_val, alpha=0.5)\n            plt.xlabel(\"Prediction\")\n            plt.ylabel(\"Predicted σ\")\n            plt.title(\"Prediction vs Uncertainty\")\n            plt.grid(True)\n            plt.show()\n\n            \n            pyro_score = official_competition_score(\n                y_val, y_pred_val, sigma_val, naive_mu_train, naive_sigma_train\n            )\n            \n            print(f\"\\nPYRO Validation Score: {pyro_score:.4f}\")\n            print(\"DIAGNOSTICS AS PER CHAT 2:\")\n            print(\"Mean pred:\", y_pred_val.mean().item())\n            print(\"Std pred:\", y_pred_val.std().item())\n            print(\"Any NaN?\", np.isnan(y_pred_val).any())\n            print(\"y_val mean/std:\", y_val.mean().item(), y_val.std().item())\n            print(\"Pred mean/std:\", y_pred_val.mean().item(), y_pred_val.std().item())\n            print(\"Sigma mean:\", sigma_val.mean().item())\n            print(y_pred_val[:5])\n            print(y_val[:5])\n            print(\"END DIAGNOSTICS AS PER CHAT 2\")\n\n            # Retrain on full dataset\n            print(\"\\\\nRetraining on full dataset...\")\n            full_model, full_guide, val_quantile_preds = train_pyro_model(\n                train_features_df, train_labels, \n                train_features_df[:100], train_labels[:100],  # Dummy validation for interface\n                feature_names, wavelengths, guide_type=\"flow\", flow_depth=1,  # Start with depth=1 for stability\n                flow_hidden_dims=[1024, 1024]  # Much larger hidden dims\n            )\n            \n            # Save final models\n            save_models(full_model, full_guide, feature_names, config.OUTPUT_PATH)\n            \n        else:  # XGBoost\n            val_quantile_preds = train_xgboost_quantiles(X_train, y_train, X_val, y_val)\n            \n            # Your existing calibration logic\n            y_pred_val, lower_val, upper_val = val_quantile_preds[0.50], val_quantile_preds[0.05], val_quantile_preds[0.95]\n            sigma_raw_val = (upper_val - lower_val) / 3.29\n            sigma_raw_val[sigma_raw_val < 0] = 1e-10\n\n            print(\"\\\\nSearching for calibration factors...\")\n            best_score, best_scaling, best_additive = -1.0, 1.0, 0.0\n            \n            for scaling in [1.0, 1.2, 1.5, 2.0, 2.5]:\n                for additive in [0.0, 0.0005, 0.001, 0.0015]:\n                    sigma_calibrated = (sigma_raw_val * scaling) + additive\n                    score = official_competition_score(y_val, y_pred_val, sigma_calibrated, naive_mu_train, naive_sigma_train)\n                    \n                    if score > best_score:\n                        best_score, best_scaling, best_additive = score, scaling, additive\n            \n            print(f\"Best XGBoost Score: {best_score:.4f} (Scale={best_scaling}, Add={best_additive})\")\n            \n            # Save calibration and retrain models\n            os.makedirs(config.OUTPUT_PATH, exist_ok=True)\n            calibration_params = {'scaling': best_scaling, 'additive': best_additive}\n            with open(os.path.join(config.OUTPUT_PATH, 'calibration_params.pkl'), 'wb') as f:\n                pickle.dump(calibration_params, f)\n            \n            with open(os.path.join(config.OUTPUT_PATH, 'feature_columns.pkl'), 'wb') as f:\n                pickle.dump(feature_names, f)\n\n            print(\"\\\\nRetraining XGBoost on full dataset...\")\n            for q in config.QUANTILES:\n                model = xgb.XGBRegressor(**config.XGB_PARAMS, objective='reg:quantileerror', quantile_alpha=q)\n                wrapper = MultiOutputRegressor(model, n_jobs=-1)\n                wrapper.fit(train_features_df, train_labels)\n                \n                model_path = os.path.join(config.OUTPUT_PATH, f'model_quantile_{q}.pkl')\n                with open(model_path, 'wb') as f:\n                    pickle.dump(wrapper, f)\n        \n        print(\"\\\\nTraining complete!\")\n\nif __name__ == '__main__':\n    \n    # Clear GPU memory at start\n    if config.USE_GPU and torch.cuda.is_available():\n        torch.cuda.empty_cache()\n    \n    try:\n        main()\n    finally:\n        # Clean up GPU memory\n        if config.USE_GPU and torch.cuda.is_available():\n            torch.cuda.empty_cache()\n            print(f\"\\\\nFinal GPU memory usage: {torch.cuda.memory_allocated(device) / 1e9:.1f} GB\")\n","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2025-08-06T03:57:10.448803Z","iopub.execute_input":"2025-08-06T03:57:10.449137Z","iopub.status.idle":"2025-08-06T03:57:24.109191Z","shell.execute_reply.started":"2025-08-06T03:57:10.449114Z","shell.execute_reply":"2025-08-06T03:57:24.108365Z"},"papermill":{"duration":38.472562,"end_time":"2025-06-28T07:57:09.008643","exception":false,"start_time":"2025-06-28T07:56:30.536081","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"Using CPU\n\\nUsing model: physics_pyro\nDevice: cpu\n\\n============================================================\n======          TRAINING MODE           ======\n============================================================\\n\nLoading pre-processed training data...\nEngineering features...\nCreated 40 features in total.\n=== TRAINING FIXED PYRO MODEL ===\nFirst, let's debug your original model...\n=== DEBUGGING PYRO MODEL ===\nX_train range: [-1.7746, 143998.8125]\ny_train range: [0.0037, 0.0887]\nX_val range: [-1.7406, 73570.2031]\ny_val range: [0.0038, 0.0798]\n\n=== Testing Deterministic Model ===\nModel mu range: [-0.517753, 0.447659]\nModel mu mean/std: 0.000403 / 0.134456\nTarget mean/std: 0.013913 / 0.009196\n⚠️  WARNING: Model mean output is very different from target!\n   This suggests the neural network isn't learning properly\n\n=== Checking Noise Parameters ===\nfgs_base_noise: 0.015875 ± nan\nairs_base_noise: 0.014777 ± nan\ntemp_noise_effect: 0.020075 ± nan\n\n=== Checking Gradient Flow ===\n\n=== Creating Fixed Model ===\nTraining fixed model for 1000 epochs...\n  Epoch    0, Loss: 3875058745340.32, Pred Mean: -2.345668\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_36/663017448.py:50: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /pytorch/aten/src/ATen/native/ReduceOps.cpp:1831.)\n  print(f\"{name}: {value.mean():.6f} ± {value.std():.6f}\")\n","output_type":"stream"},{"name":"stdout","text":"  Epoch  100, Loss: 3069190864892.32, Pred Mean: 1.750040\n  Epoch  200, Loss: 2313906814972.32, Pred Mean: 4.256048\n  Epoch  300, Loss: 2276747902972.32, Pred Mean: 0.444048\n  Epoch  400, Loss: 1824365608956.32, Pred Mean: 3.308710\n  Epoch  500, Loss: 1992954871804.32, Pred Mean: 0.018357\n  Epoch  600, Loss: 1245510369276.32, Pred Mean: 0.476315\n  Epoch  700, Loss: 1512610725884.32, Pred Mean: -3.699025\n  Epoch  800, Loss: 935651377148.32, Pred Mean: 4.950878\n  Epoch  900, Loss: 1058726608892.32, Pred Mean: 3.941646\nGenerating final predictions...\n\n=== FIXED MODEL RESULTS ===\ny_val mean/std: 0.014979 0.011349\nPred mean/std: 2.244731 289.396454\nFinal loss: 1517572587516.32\nNoise parameter: 1.020108\n\\nPHYSICS_PYRO Validation Score: 0.0000\nPyro models saved to: /kaggle/working/ariel-data-2025-27\nDIAGNOSTICS AS PER CHAT 1:\nMean absolute error: 215.55287813919904\nMean normalized error: 192.09411454087055\nMax normalized error: 2763.2904180246\nMin normalized error: 0.004134659465319382\nEND DIAGNOSTICS AS PER CHAT 1\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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\n"},"metadata":{}},{"name":"stdout","text":"\nPYRO Validation Score: 0.0000\nDIAGNOSTICS AS PER CHAT 2:\nMean pred: 2.2447307109832764\nStd pred: 289.3964538574219\nAny NaN? False\ny_val mean/std: 0.014978743488125727 0.011348901591756461\nPred mean/std: 2.2447307109832764 289.3964538574219\nSigma mean: 1.1221201419830322\n[[-246.2074      131.07228     238.0451     ... -404.60233\n   179.31581      81.8921    ]\n [ -72.08229     312.1495      -97.0846     ...   25.13146\n   496.26184    -258.57672   ]\n [-169.41286     181.78009     111.82415    ...    0.95880973\n   294.94763    -301.71664   ]\n [-261.2075      833.1625      -21.09786    ... -337.60507\n    24.755352   -320.9482    ]\n [-534.35205     448.92368     210.6199     ... -178.1143\n   166.47708    -135.01509   ]]\n[[0.00580957 0.0056696  0.00566773 ... 0.00556971 0.00557163 0.00555928]\n [0.02132329 0.02150939 0.02150258 ... 0.02125517 0.02125705 0.02125592]\n [0.00518672 0.00515674 0.00515666 ... 0.00516809 0.00516835 0.00516852]\n [0.00639365 0.00638071 0.0063805  ... 0.00638365 0.00638342 0.00638337]\n [0.01639064 0.0163704  0.01637054 ... 0.01633427 0.01633436 0.01633411]]\nEND DIAGNOSTICS AS PER CHAT 2\n\\nRetraining on full dataset...\n=== TRAINING FIXED PYRO MODEL ===\nFirst, let's debug your original model...\n=== DEBUGGING PYRO MODEL ===\nX_train range: [-1.7746, 143998.8125]\ny_train range: [0.0037, 0.0887]\nX_val range: [-1.7406, 73570.2031]\ny_val range: [0.0038, 0.0798]\n\n=== Testing Deterministic Model ===\nModel mu range: [-0.347786, 0.409758]\nModel mu mean/std: -0.004381 / 0.112622\nTarget mean/std: 0.015433 / 0.011140\n⚠️  WARNING: Model mean output is very different from target!\n   This suggests the neural network isn't learning properly\n\n=== Checking Noise Parameters ===\nfgs_base_noise: 0.019868 ± nan\nairs_base_noise: 0.013416 ± nan\ntemp_noise_effect: 0.016246 ± nan\n\n=== Checking Gradient Flow ===\n\n=== Creating Fixed Model ===\nTraining fixed model for 1000 epochs...\n  Epoch    0, Loss: 5720769560572.16, Pred Mean: 19.831944\n  Epoch  100, Loss: 5945237700604.16, Pred Mean: 21.337124\n  Epoch  200, Loss: 3720954773500.16, Pred Mean: 20.724188\n  Epoch  300, Loss: 3274849648636.16, Pred Mean: 16.151237\n  Epoch  400, Loss: 2950356533244.16, Pred Mean: 20.862276\n  Epoch  500, Loss: 3105445380092.16, Pred Mean: 15.681097\n  Epoch  600, Loss: 2527611322364.16, Pred Mean: 18.779289\n  Epoch  700, Loss: 2356936179708.16, Pred Mean: 16.826550\n  Epoch  800, Loss: 1949175250940.16, Pred Mean: 11.616050\n  Epoch  900, Loss: 2639180595196.16, Pred Mean: 13.599610\nGenerating final predictions...\n\n=== FIXED MODEL RESULTS ===\ny_val mean/std: 0.015805 0.011999\nPred mean/std: 14.212295 329.220428\nFinal loss: 1610298294268.16\nNoise parameter: 1.017088\nPyro models saved to: /kaggle/working/ariel-data-2025-27\n\\nTraining complete!\n","output_type":"stream"}],"execution_count":135},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}